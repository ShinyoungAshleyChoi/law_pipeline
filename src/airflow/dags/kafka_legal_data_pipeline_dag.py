"""
Kafka ê¸°ë°˜ ë²•ì œì²˜ API ë°ì´í„° íŒŒì´í”„ë¼ì¸ Airflow DAG
ë¬´ì¤‘ë‹¨ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ Kafka í†µí•© ë²„ì „
"""
from datetime import datetime, timedelta, date
from typing import Dict, Any
import uuid
import json
import asyncio

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago
from airflow.utils.task_group import TaskGroup
from airflow.models import Variable
from airflow.exceptions import AirflowException, AirflowSkipException
from airflow.utils.email import send_email

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ìž„í¬íŠ¸
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../..'))

from src.api.kafka_client import kafka_integrated_client
from src.database.repository import LegalDataRepository
from src.notifications.slack_service import slack_service
from src.logging_config import get_logger
from src.kafka.models import EventType

logger = get_logger(__name__)

# DAG ê¸°ë³¸ ì„¤ì •
DEFAULT_ARGS = {
    'owner': 'legal-data-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'retry_exponential_backoff': True,
    'max_retry_delay': timedelta(minutes=15),
    'execution_timeout': timedelta(hours=2),
    'sla': timedelta(hours=3),
}

# Kafka ê¸°ë°˜ DAG ì •ì˜
dag = DAG(
    'kafka_legal_data_pipeline',
    default_args=DEFAULT_ARGS,
    description='Kafka ê¸°ë°˜ ë²•ì œì²˜ API ë°ì´í„° íŒŒì´í”„ë¼ì¸ - ë¬´ì¤‘ë‹¨ ì„œë¹„ìŠ¤',
    schedule_interval='0 2 * * *',  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰
    catchup=False,
    max_active_runs=1,
    tags=['legal', 'kafka', 'pipeline', 'zero-downtime'],
    doc_md="""
    # Kafka ê¸°ë°˜ ë²•ì œì²˜ API ë°ì´í„° íŒŒì´í”„ë¼ì¸
    
    ## ê°œìš”
    ë¬´ì¤‘ë‹¨ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•´ Kafkaë¥¼ í™œìš©í•œ ë²•ì œì²˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ìž…ë‹ˆë‹¤.
    
    ## ì£¼ìš” íŠ¹ì§•
    - **ë¬´ì¤‘ë‹¨ ì„œë¹„ìŠ¤**: API ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ì´ ë°ì´í„° ì—…ë°ì´íŠ¸
    - **ë†’ì€ ì‹ ë¢°ì„±**: Kafka ë©”ì‹œì§€ ì˜ì†ì„±ìœ¼ë¡œ ë°ì´í„° ì†ì‹¤ ë°©ì§€
    - **í™•ìž¥ì„±**: Producer/Consumer ë¶„ë¦¬ë¡œ ìˆ˜í‰ í™•ìž¥ ê°€ëŠ¥
    - **ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì²˜ë¦¬ ìƒíƒœ ì¶”ì 
    
    ## ë°ì´í„° í”Œë¡œìš°
    1. **Producer**: ë²•ì œì²˜ API â†’ Kafka Topics
    2. **Consumer**: Kafka Topics â†’ MySQL Database
    3. **Monitoring**: ì²˜ë¦¬ ìƒíƒœ ë° í†µê³„ ì¶”ì 
    """,
    params={
        'force_full_sync': False,
        'target_date': None,
        'batch_size': 100,
        'notification_enabled': True,
        'kafka_enabled': True
    }
)

# ==================== í—¬í¼ í•¨ìˆ˜ ====================

def run_async_task(async_func, *args, **kwargs):
    """ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸° í™˜ê²½ì—ì„œ ì‹¤í–‰"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(async_func(*args, **kwargs))
    finally:
        loop.close()

def kafka_produce_legal_data(**context) -> Dict[str, Any]:
    """Kafka Producerë¥¼ í†µí•œ ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì†¡"""
    logger.info("Kafka Producer ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘")
    
    async def _produce_data(sync_date, batch_size):
        async with kafka_integrated_client:
            return await kafka_integrated_client.collect_and_publish_laws(
                last_sync_date=sync_date,
                batch_size=batch_size
            )
    
    try:
        # íŒŒë¼ë¯¸í„° í™•ì¸
        params = context.get('params', {})
        batch_size = params.get('batch_size', 100)
        
        # ë§ˆì§€ë§‰ ë™ê¸°í™” ë‚ ì§œ ì¡°íšŒ
        repository = LegalDataRepository()
        sync_date = repository.get_last_sync_date("INCREMENTAL")
        if not sync_date:
            sync_date = date.today() - timedelta(days=7)
        
        # Kafka Producer ì‹¤í–‰
        result = run_async_task(_produce_data, sync_date, batch_size)
        
        logger.info("Kafka Producer ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ",
                   sent_laws=result.get('sent_laws', 0),
                   failed_laws=result.get('failed_laws', 0))
        
        return result
        
    except Exception as e:
        logger.error("Kafka Producer ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨", error=str(e))
        
        # ì˜¤ë¥˜ ì•Œë¦¼
        slack_service.send_error_alert(
            title="Kafka Producer ì‹¤í–‰ ì‹¤íŒ¨",
            message=f"ì˜¤ë¥˜: {str(e)}",
            context={'dag_id': context['dag'].dag_id}
        )
        
        raise

def send_completion_notification(**context) -> None:
    """ì™„ë£Œ ì•Œë¦¼ ë°œì†¡"""
    logger.info("ì™„ë£Œ ì•Œë¦¼ ë°œì†¡ ì‹œìž‘")
    
    try:
        # íŒŒë¼ë¯¸í„° í™•ì¸
        params = context.get('params', {})
        if not params.get('notification_enabled', True):
            logger.info("ì•Œë¦¼ì´ ë¹„í™œì„±í™”ë˜ì–´ ìžˆìŠµë‹ˆë‹¤")
            return
        
        # ê²°ê³¼ ë°ì´í„° ìˆ˜ì§‘
        produce_result = context['task_instance'].xcom_pull(
            task_ids='kafka_produce_legal_data'
        )
        
        if not produce_result:
            logger.warning("Producer ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # í†µê³„ ì •ë³´ ìƒì„±
        sent_laws = produce_result.get('sent_laws', 0)
        failed_laws = produce_result.get('failed_laws', 0)
        duration = produce_result.get('duration_seconds', 0)
        
        # ì„±ê³µ/ì‹¤íŒ¨ ê²°ì •
        is_success = failed_laws == 0
        
        # ë©”ì‹œì§€ ìƒì„±
        status_icon = "âœ…" if is_success else "âš ï¸"
        status_text = "ì„±ê³µ" if is_success else "ë¶€ë¶„ ì„±ê³µ"
        
        message = f"""
{status_icon} Kafka ê¸°ë°˜ ë²•ì œì²˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ

ðŸ“Š **ì²˜ë¦¬ ê²°ê³¼:**
â€¢ ì²˜ë¦¬ëœ ë²•ë ¹: {sent_laws}ê°œ
â€¢ ì‹¤íŒ¨í•œ ë²•ë ¹: {failed_laws}ê°œ
â€¢ ì²˜ë¦¬ ì‹œê°„: {duration:.1f}ì´ˆ
â€¢ ìƒíƒœ: {status_text}

ðŸ”„ **Kafka í†µí•©:**
â€¢ Producer â†’ Consumer ë¹„ë™ê¸° ì²˜ë¦¬
â€¢ ë¬´ì¤‘ë‹¨ ì„œë¹„ìŠ¤ ë³´ìž¥
â€¢ ë©”ì‹œì§€ ì˜ì†ì„± í™•ë³´
        """.strip()
        
        # ìŠ¬ëž™ ì•Œë¦¼ ë°œì†¡
        if is_success:
            slack_service.send_info_message(
                title="Kafka ê¸°ë°˜ ë²•ì œì²˜ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ",
                message=message
            )
        else:
            slack_service.send_error_alert(
                title="Kafka ê¸°ë°˜ ë²•ì œì²˜ íŒŒì´í”„ë¼ì¸ ë¶€ë¶„ ì‹¤íŒ¨",
                message=message,
                context=produce_result
            )
        
        logger.info("ì™„ë£Œ ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
        
    except Exception as e:
        logger.error("ì™„ë£Œ ì•Œë¦¼ ë°œì†¡ ì‹¤íŒ¨", error=str(e))

# ==================== DAG íƒœìŠ¤í¬ ì •ì˜ ====================

# Kafka Producer ë°ì´í„° ìˆ˜ì§‘
kafka_produce_task = PythonOperator(
    task_id='kafka_produce_legal_data',
    python_callable=kafka_produce_legal_data,
    dag=dag,
    execution_timeout=timedelta(hours=1),
    doc_md="Kafka Producerë¥¼ í†µí•´ ë²•ì œì²˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  í† í”½ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤."
)

# ì™„ë£Œ ì•Œë¦¼
completion_notification_task = PythonOperator(
    task_id='send_completion_notification',
    python_callable=send_completion_notification,
    dag=dag,
    doc_md="íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤."
)

# ==================== íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì • ====================

kafka_produce_task >> completion_notification_task
